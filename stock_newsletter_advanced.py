"""
ì£¼ì‹ ì‹œì¥ RAG ê¸°ë°˜ ë‰´ìŠ¤ë ˆí„° ì‹œìŠ¤í…œ - ê³ ê¸‰ ë²„ì „
ì¶”ê°€ ê¸°ëŠ¥: ìºì‹±, ë¡œê¹…, ì„¤ì • íŒŒì¼, ì—ëŸ¬ ë³µêµ¬
"""

import os
import json
import logging
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional
import pickle

import requests
from bs4 import BeautifulSoup
import pandas as pd
import matplotlib.pyplot as plt
import google.generativeai as genai

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('/home/claude/stock_newsletter.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


class Config:
    """ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    DEFAULT_CONFIG = {
        "cache_duration_minutes": 30,
        "max_retries": 3,
        "timeout_seconds": 10,
        "output_directory": "/mnt/user-data/outputs",
        "cache_directory": "/home/claude/.cache",
        "gemini_model": "gemini-2.0-flash-exp",
        "top_stocks_count": 10,
        "news_count": 5,
    }
    
    def __init__(self, config_path: str = "/home/claude/config.json"):
        self.config_path = config_path
        self.config = self.load_config()
    
    def load_config(self) -> Dict:
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        if os.path.exists(self.config_path):
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    user_config = json.load(f)
                    return {**self.DEFAULT_CONFIG, **user_config}
            except Exception as e:
                logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")
        return self.DEFAULT_CONFIG.copy()
    
    def save_config(self):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            with open(self.config_path, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            logger.info("ì„¤ì • íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        except Exception as e:
            logger.error(f"ì„¤ì • íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get(self, key: str, default=None):
        """ì„¤ì •ê°’ ì¡°íšŒ"""
        return self.config.get(key, default)


class CacheManager:
    """ìºì‹œ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, cache_dir: str, duration_minutes: int = 30):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self.duration = timedelta(minutes=duration_minutes)
    
    def get_cache_path(self, key: str) -> Path:
        """ìºì‹œ íŒŒì¼ ê²½ë¡œ ìƒì„±"""
        return self.cache_dir / f"{key}.cache"
    
    def is_valid(self, key: str) -> bool:
        """ìºì‹œ ìœ íš¨ì„± ê²€ì¦"""
        cache_path = self.get_cache_path(key)
        if not cache_path.exists():
            return False
        
        # íŒŒì¼ ìˆ˜ì • ì‹œê°„ í™•ì¸
        mtime = datetime.fromtimestamp(cache_path.stat().st_mtime)
        return datetime.now() - mtime < self.duration
    
    def get(self, key: str) -> Optional[any]:
        """ìºì‹œ ë°ì´í„° ì¡°íšŒ"""
        if not self.is_valid(key):
            return None
        
        try:
            cache_path = self.get_cache_path(key)
            with open(cache_path, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            logger.warning(f"ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def set(self, key: str, data: any):
        """ìºì‹œ ë°ì´í„° ì €ì¥"""
        try:
            cache_path = self.get_cache_path(key)
            with open(cache_path, 'wb') as f:
                pickle.dump(data, f)
            logger.info(f"ìºì‹œ ì €ì¥ ì™„ë£Œ: {key}")
        except Exception as e:
            logger.error(f"ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def clear(self, key: Optional[str] = None):
        """ìºì‹œ ì‚­ì œ"""
        if key:
            cache_path = self.get_cache_path(key)
            if cache_path.exists():
                cache_path.unlink()
        else:
            # ëª¨ë“  ìºì‹œ ì‚­ì œ
            for cache_file in self.cache_dir.glob("*.cache"):
                cache_file.unlink()
        logger.info(f"ìºì‹œ ì‚­ì œ ì™„ë£Œ: {key or 'all'}")


class EnhancedStockDataCollector:
    """ê°œì„ ëœ ì£¼ì‹ ë°ì´í„° ìˆ˜ì§‘ í´ë˜ìŠ¤ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""
    
    def __init__(self, config: Config, cache_manager: CacheManager):
        self.config = config
        self.cache = cache_manager
        self.base_url = "https://m.stock.naver.com"
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
    
    def _fetch_with_retry(self, url: str, cache_key: str) -> Optional[BeautifulSoup]:
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ HTTP ìš”ì²­"""
        
        # ìºì‹œ í™•ì¸
        cached_data = self.cache.get(cache_key)
        if cached_data:
            logger.info(f"ìºì‹œ ì‚¬ìš©: {cache_key}")
            return cached_data
        
        max_retries = self.config.get('max_retries', 3)
        timeout = self.config.get('timeout_seconds', 10)
        
        for attempt in range(max_retries):
            try:
                response = requests.get(url, headers=self.headers, timeout=timeout)
                response.raise_for_status()
                soup = BeautifulSoup(response.content, 'html.parser')
                
                # ìºì‹œ ì €ì¥
                self.cache.set(cache_key, soup)
                logger.info(f"ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ: {cache_key}")
                return soup
                
            except requests.RequestException as e:
                logger.warning(f"ì‹œë„ {attempt + 1}/{max_retries} ì‹¤íŒ¨: {e}")
                if attempt == max_retries - 1:
                    logger.error(f"ìµœì¢… ì‹¤íŒ¨: {url}")
                    return None
        
        return None
    
    def collect_market_indices(self) -> List[Dict]:
        """ì£¼ìš” ì§€ìˆ˜ ì •ë³´ ìˆ˜ì§‘ (ê°œì„ ëœ ë²„ì „)"""
        soup = self._fetch_with_retry(
            f"{self.base_url}/index.naver",
            "market_indices"
        )
        
        if not soup:
            logger.error("ì§€ìˆ˜ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨")
            return self._get_fallback_indices()
        
        # ì‹¤ì œ íŒŒì‹± ë¡œì§ì€ ë„¤ì´ë²„ ì¦ê¶Œì˜ HTML êµ¬ì¡°ì— ë§ì¶° êµ¬í˜„
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„° ë°˜í™˜
        return self._get_fallback_indices()
    
    def _get_fallback_indices(self) -> List[Dict]:
        """í´ë°± ë°ì´í„° (ìˆ˜ì§‘ ì‹¤íŒ¨ ì‹œ)"""
        logger.info("í´ë°± ë°ì´í„° ì‚¬ìš©")
        return [
            {
                "index_name": "KOSPI",
                "current_value": 2500.0,
                "change_value": 10.5,
                "change_rate": 0.42,
                "timestamp": datetime.now().isoformat()
            },
            {
                "index_name": "KOSDAQ",
                "current_value": 850.0,
                "change_value": -5.2,
                "change_rate": -0.61,
                "timestamp": datetime.now().isoformat()
            }
        ]
    
    def collect_top_stocks(self, category: str = 'rise') -> List[Dict]:
        """ìƒìŠ¹/í•˜ë½ ìƒìœ„ ì¢…ëª© ìˆ˜ì§‘"""
        cache_key = f"top_stocks_{category}"
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì›¹ ìŠ¤í¬ë˜í•‘ ë¡œì§ ì¶”ê°€
        # ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ ë°ì´í„°
        sample_stocks = [
            {"rank": i+1, "name": f"ì¢…ëª©{i+1}", "current_price": 50000 + i*1000,
             "change_rate": 5.0 - i*0.3, "category": category}
            for i in range(self.config.get('top_stocks_count', 10))
        ]
        
        return sample_stocks
    
    def collect_market_news(self) -> List[Dict]:
        """ì‹œì¥ ì£¼ìš” ë‰´ìŠ¤ ìˆ˜ì§‘"""
        cache_key = "market_news"
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ë‰´ìŠ¤ íŒŒì‹± ë¡œì§ ì¶”ê°€
        return [
            {"title": f"ë‰´ìŠ¤ ì œëª© {i+1}", "summary": f"ìš”ì•½ ë‚´ìš© {i+1}"}
            for i in range(self.config.get('news_count', 5))
        ]


class AdvancedStockNewsletterSystem:
    """ê³ ê¸‰ í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self, gemini_api_key: str, config_path: Optional[str] = None):
        self.config = Config(config_path) if config_path else Config()
        self.cache = CacheManager(
            self.config.get('cache_directory'),
            self.config.get('cache_duration_minutes')
        )
        self.collector = EnhancedStockDataCollector(self.config, self.cache)
        
        # Gemini ì„¤ì •
        genai.configure(api_key=gemini_api_key)
        self.model = genai.GenerativeModel(self.config.get('gemini_model'))
        
        logger.info("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def process_query(self, user_input: str) -> Dict:
        """ì‚¬ìš©ì ì¿¼ë¦¬ ì²˜ë¦¬ (í–¥ìƒëœ ë²„ì „)"""
        try:
            logger.info(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì‹œì‘: {user_input}")
            
            # 1. ë°ì´í„° ìˆ˜ì§‘
            indices = self.collector.collect_market_indices()
            rising = self.collector.collect_top_stocks('rise')
            falling = self.collector.collect_top_stocks('fall')
            news = self.collector.collect_market_news()
            
            # 2. ë°ì´í„° ì²˜ë¦¬
            processed = self._process_data(indices, rising, falling)
            
            # 3. ì‹œê°í™”
            images = self._create_visualizations(processed)
            
            # 4. ë‰´ìŠ¤ë ˆí„° ìƒì„±
            newsletter = self._generate_newsletter(processed, news, user_input)
            
            result = {
                'success': True,
                'newsletter': newsletter,
                'images': images,
                'timestamp': datetime.now().isoformat(),
                'cached_data': self.cache.is_valid('market_indices')
            }
            
            logger.info("ì¿¼ë¦¬ ì²˜ë¦¬ ì™„ë£Œ")
            return result
            
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }
    
    def _process_data(self, indices, rising, falling) -> Dict:
        """ë°ì´í„° ì²˜ë¦¬"""
        return {
            'indices': pd.DataFrame(indices),
            'rising': pd.DataFrame(rising),
            'falling': pd.DataFrame(falling)
        }
    
    def _create_visualizations(self, data_dict: Dict) -> List[str]:
        """ì‹œê°í™” ìƒì„±"""
        output_dir = self.config.get('output_directory')
        os.makedirs(output_dir, exist_ok=True)
        
        images = []
        
        # ì§€ìˆ˜ ì°¨íŠ¸
        try:
            fig, ax = plt.subplots(figsize=(10, 6))
            if 'change_rate' in data_dict['indices'].columns:
                ax.bar(data_dict['indices']['index_name'], 
                       data_dict['indices']['change_rate'])
                ax.set_title('Market Indices Performance')
                plt.tight_layout()
                
                path = f"{output_dir}/indices_chart.png"
                plt.savefig(path, dpi=150)
                plt.close()
                images.append(path)
        except Exception as e:
            logger.error(f"ì‹œê°í™” ì˜¤ë¥˜: {e}")
        
        return images
    
    def _generate_newsletter(self, data: Dict, news: List, query: str) -> str:
        """ë‰´ìŠ¤ë ˆí„° ìƒì„±"""
        try:
            context = self._create_context(data, news)
            
            prompt = f"""
ë‹¹ì‹ ì€ ì „ë¬¸ ê¸ˆìœµ ì• ë„ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ì ì§ˆì˜: {query}

ë°ì´í„°:
{context}

ìœ„ ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ì ì´ê³  í†µì°°ë ¥ ìˆëŠ” ì‹œì¥ ë¶„ì„ ë‰´ìŠ¤ë ˆí„°ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
            
            response = self.model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logger.error(f"ë‰´ìŠ¤ë ˆí„° ìƒì„± ì˜¤ë¥˜: {e}")
            return f"ë‰´ìŠ¤ë ˆí„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"
    
    def _create_context(self, data: Dict, news: List) -> str:
        """RAG ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        context = f"### ì‹œì¥ ì§€ìˆ˜\n{data['indices'].to_string()}\n\n"
        context += f"### ìƒìŠ¹ ì¢…ëª©\n{data['rising'].head().to_string()}\n\n"
        context += f"### í•˜ë½ ì¢…ëª©\n{data['falling'].head().to_string()}\n\n"
        context += "### ì£¼ìš” ë‰´ìŠ¤\n"
        for item in news:
            context += f"- {item['title']}\n"
        return context
    
    def clear_cache(self):
        """ìºì‹œ ì´ˆê¸°í™”"""
        self.cache.clear()
        logger.info("ëª¨ë“  ìºì‹œ ì‚­ì œ ì™„ë£Œ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=" * 60)
    print("ğŸ“ˆ ê³ ê¸‰ ì£¼ì‹ ì‹œì¥ RAG ë‰´ìŠ¤ë ˆí„° ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    api_key = input("\nğŸ”‘ Gemini API í‚¤: ").strip()
    if not api_key:
        print("âŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
        return
    
    system = AdvancedStockNewsletterSystem(api_key)
    
    while True:
        print("\n" + "-" * 60)
        print("ëª…ë ¹ì–´: 'ì˜¤ëŠ˜ì êµ­ë‚´ ì‹œì¥', 'cache clear', 'exit'")
        user_input = input("ğŸ’¬ ì…ë ¥: ").strip()
        
        if user_input.lower() == 'exit':
            break
        elif user_input.lower() == 'cache clear':
            system.clear_cache()
            print("âœ… ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
            continue
        
        result = system.process_query(user_input)
        
        if result['success']:
            print("\n" + "=" * 60)
            print("âœ… ë‰´ìŠ¤ë ˆí„° ìƒì„± ì™„ë£Œ!")
            print("=" * 60)
            print(result['newsletter'])
            
            if result.get('cached_data'):
                print("\nğŸ’¾ ìºì‹œëœ ë°ì´í„° ì‚¬ìš©ë¨")
        else:
            print(f"\nâŒ ì˜¤ë¥˜: {result.get('error')}")


if __name__ == "__main__":
    main()
